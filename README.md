# Repository zum Onlinekurs Transformer Modelle und Deep Learning mit Hugging Face und fastai
Der Kurs Tranformer Modelle (Encoder - Decoder Deep Learning Modellarchitekturen) kann direkt über die ai-academy gebucht werden: [Kursbeschreibung auf der ai-academy](https://academy.we-make.ai/courses/transformer-modelle-und-fastai-deep-learning/)

Dieser Kurs beschäftigt sich mit dem Thema Encoder-Decoder-Modellarchitekturen im Deep Learning und darauf basierenden Anwendungsfällen im Bereich Natural Language Understanding.

## Was lerne ich in diesem Kurs?

Wir besprechen, wie Encoder-Decoder Modelle (insbesondere Transformer Modelle wie GPT2 Modelle oder BERT-Architekturen) aufgebaut sind und welche Schritte während des Trainings eines solchen Modells ablaufen.

Der große Nutzen dieser vortrainierten Modellarchitekturen besteht in der Anwendung des Transfer-Learning Konzepts. Das bedeutet, wir können uns riesige, vortrainierte Modellarchitekturen zu Nutze machen und mit relativ wenig Aufwand für unseren konkreten Anwendungsfall trainieren.

Wie können wir mittel one-shot-classification Texte einer bestimmten Kategorie zuordnen?

Wie integrieren wir Modelle aus dem Hugging Face Projekt in unsere eigenen Deep Learning Projekt auf Basis der fastai Bibliothek?

Neben dem theoretischen Input entwickeln wir anhand von Jupyther Notebooks Anwendungsbeispiele und gehen den implementierten Code unserer KI-Anwendungen Schritt für Schritt gemeinsam durch.

## Lernziele Transformer Modelle, Deep Learning und fastai

Folgende Lernziele verfolgen wir mit dem Kurs Transformer Modelle (Encoder/Decoder Architekturen) und Deep Learning:

Du lernst das erforderliche theoretische Basiswissen, um Transformer Modellarchitekturen im Deep Learning zu verstehen.
Du kannst das Funktionsprinzip von Transformer Modellen wie BERT oder GPT2 verstehen.
Du lernst, wie du Transformer Modelle in fastai Projekt integrieren kannst
Du lernst verschiedene Bibliotheken wie Blurr oder FastHugs kennen.
Mithilfe von Bibliotheken integrieren wir vortrainierte Transformermodelle mittels Hugging-Face und fastai Framework.
Für wen ist dieser KI Spezialkurs interessant?
Dieser Kurs richtet sich an Interessierte aus dem Bereich künstliche Intelligenz, die bereits ein Grundwissen über Deep Learning und die fastai Bibliothek mitbringen und lernen möchten, wie man mithilfe von Hugging Face schnell und einfach Transformer Modelle mit fastai integrieren kann.
